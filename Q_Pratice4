import numpy as np
import random
import matplotlib.pyplot as plt
from matplotlib import colors

# 환경 설정
n_rows, n_cols = 5, 5  # 격자 크기
n_states = n_rows * n_cols  # 상태의 개수
n_actions = 4  # 행동의 개수 (상, 하, 좌, 우 이동)
q_table = np.zeros((n_states, n_actions))  # Q-테이블 초기화

pest_infestation = np.random.choice([0, 1], size=n_states, p=[0.8, 0.2])  # 병충해 유무 무작위 할당 (80%는 없음, 20%는 병충해 있음)

# Q-learning 파라미터
learning_rate = 0.1
discount_factor = 0.9
epsilon = 0.1
n_episodes = 100  # 학습할 에피소드 수

# 격자에서의 위치를 상태로 변환
def state_from_location(x, y):
    return x * n_cols + y

# 행동을 취했을 때의 상태 변화 함수
def update_environment(state, action):
    x, y = divmod(state, n_cols)
    if action == 0:  # 상
        x = max(0, x - 1)
    elif action == 1:  # 하
        x = min(n_rows - 1, x + 1)
    elif action == 2:  # 좌
        y = max(0, y - 1)
    elif action == 3:  # 우
        y = min(n_cols - 1, y + 1)
    
    next_state = state_from_location(x, y)
    reward = 1 if pest_infestation[next_state] == 1 else -1  # 병충해 발견시 보상, 그렇지 않으면 벌점
    return next_state, reward

def choose_action(state):
    if random.uniform(0, 1) < epsilon:
        return random.choice(range(n_actions))  # 무작위 행동 선택
    else:
        return np.argmax(q_table[state, :])  # 최적의 행동 선택

# 시각화 함수
def visualize_grid_world(episode, steps, state):
    grid = np.reshape(pest_infestation, (n_rows, n_cols))
    fig, ax = plt.subplots()
    cmap = colors.ListedColormap(['white', 'green'])
    ax.imshow(grid, cmap=cmap)

    x, y = divmod(state, n_cols)
    ax.plot(y, x, 'ro')  # 현재 위치 표시

    for i in range(n_states):
        ax.text(i % n_cols, i // n_cols, str(i), va='center', ha='center')

    ax.set_title(f'Episode: {episode+1}, Step: {steps+1}')
    plt.show()

# Q-learning 알고리즘과 시각화
for episode in range(n_episodes):
    state = random.randint(0, n_states - 1)  # 무작위 초기 상태
    steps = 0

    while True:
        visualize_grid_world(episode, steps, state)  # 현재 상태 시각화
        action = choose_action(state)
        next_state, reward = update_environment(state, action)

        old_value = q_table[state, action]
        next_max = np.max(q_table[next_state, :])

        # Q-테이블 업데이트
        new_value = (1 - learning_rate) * old_value + learning_rate * (reward + discount_factor * next_max)
        q_table[state, action] = new_value

        state = next_state
        steps += 1

        if pest_infestation[state] == 1:  # 병충해 발견시 에피소드 종료
            break

print("학습된 Q-테이블:")
print(q_table)
